name: daily-scraper-and-report

on:
  schedule:
    - cron: '54 16 * * *'  # Adjust cron as needed
  workflow_dispatch:

jobs:
  scrape-and-email:
    runs-on: ubuntu-latest
    steps:
      # Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4

      # Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      # Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install webdriver-manager selenium beautifulsoup4 pandas smtplib

      # Update CA certificates to fix SSL verification issues
      - name: Update CA certificates
        run: sudo apt-get install --reinstall -y ca-certificates

      # Install Google Chrome
      - name: Install Google Chrome
        run: |
          wget -q -O google-chrome.deb https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo dpkg -i google-chrome.deb || sudo apt-get install -f -y

      # Install ChromeDriver
      # - name: Install ChromeDriver
      #   run: |
      #     wget -q -O chromedriver.zip https://chromedriver.storage.googleapis.com/$(curl -sS https://chromedriver.storage.googleapis.com/LATEST_RELEASE)/chromedriver_linux64.zip
      #     unzip chromedriver.zip -d /usr/local/bin/
      #     chmod +x /usr/local/bin/chromedriver

      # Run the scraper and send email
      - name: Run scraper and email script
        env:
          USER_EMAIL: ${{ secrets.USER_EMAIL }}
          USER_PASSWORD: ${{ secrets.USER_PASSWORD }}
        run: python scraper.py
